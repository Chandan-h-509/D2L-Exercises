{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.3 Linear Algebra"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1. Prove that the transpose of a matrix $A$ʼs transpose is $ A: (A^⊤)^⊤ = A $."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the definition of transpose, $(A)_{ij} = (A^T)_{ji}$, where the subscripts represent the row and column indices. Replacing $A$ by $A^T$ in the above equation, we get $(A^T)_{ij} = ((A^T)^T)_{ji}$. Using the first eqaution in the second, we get $(A)_{ji} = ((A^T)^T)_{ji}$. Dropping the indices, we the get the desired result, $(A^⊤)^⊤ = A$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2. Given two matrices $A$ and $B$, show that the sum of transposes is equal to the transpose of a sum: $ A^⊤ + B^T = (A + B)^⊤ $."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the definition of transpose, $(A)_{ij} = (A^T)_{ji}$, where the subscripts represent the row and column indices. $(A^T + B^T)_{ij} = (A^T_{ij} + B^T_{ij}) = (A_{ji} + B_{ji}) = (A + B)_{ji} = ((A + B)^T)_{ij}$. From the equality, and dropping the indices, $A^T + B^T = (A + B)^T$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q3. Given any square matrix  $A$, is $ A + A^⊤ $ always symmetric? Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the definition of symmetric matrices, if $A$ is symmetric, $A_{ij} = A_{ji}$. From the definition of transpose, $(A)_{ij} = (A^T)_{ji}$. Now we have, $(A + A^T)_{ij} = A_{ij} + A^T_{ij} = A^T_{ji} + A_{ji} = (A^T + A)_{ji}$. From the equality, $(A + A^T)_{ij} = (A^T + A)_{ji}$, hence $A + A^T$ is always symmetric."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q4. We defined the tensor `X` of shape (2, 3, 4) in this section. What is the output of `len(X)`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "X = torch.arange(24).reshape(2, 3, 4)\n",
    "print(len(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q5. For a tensor `X` of arbitrary shape, does `len(X)` always correspond to the length of a certain axis of `X`? What is that axis?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As infered from the above example, `len(X)` prints the length of the first axis (`0`th axis)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q6.Run `A / A.sum(axis=1)` and see what happens. Can you analyze the reason?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (4) must match the size of tensor b (5) at non-singleton dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-d196eadd45a4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mA\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mA\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mA\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m: The size of tensor a (4) must match the size of tensor b (5) at non-singleton dimension 1"
     ]
    }
   ],
   "source": [
    "A = torch.arange(20).reshape(5, 4)\n",
    "A / A.sum(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`A` is a tensor of shape (5, 4). `A.sum(axis=1)` results in a tensor of shape (5,)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q7. When traveling between two points in Manhattan, what is the distance that you need to cover in terms of the coordinates, i.e., in terms of avenues and streets? Can you travel diagonally?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ans."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q8. Consider a tensor with shape (2, 3, 4). What are the shapes of the summation outputs along axis 0, 1, and 2?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Summation along a particular axis, in effect, squishes (sums) along that axis and hence cutting it down. Hence summing a tensor of shape (2, 3, 4) along:\n",
    "* axis=0, reduces it to a tensor of shape (3, 4)\n",
    "* axis=1, reduces it to a tensor of shape (2, 4)\n",
    "* axis=2, reduces it to a tensor of shape (2, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q9. Feed a tensor with 3 or more axes to the `linalg.norm` function and observe its output. What does this function compute for tensors of arbitrary shape?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 2, 2])\n"
     ]
    }
   ],
   "source": [
    "x = torch.Tensor([[[3, 4], [3, 4]], \n",
    "                  [[3, 4], [3, 4]]])\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(10.)\n"
     ]
    }
   ],
   "source": [
    "print(torch.norm(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The L2 norm of tensor with 3 or more axes behaves similar to the norm of a vector or a matrix. It gives the square-root of the sum of squares of all elements present in the tensor."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
