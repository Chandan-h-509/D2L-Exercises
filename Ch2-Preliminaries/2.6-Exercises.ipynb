{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.2 Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1. We conducted $m = 500$ groups of experiments where each group draws $n = 10$ samples. Vary $m$ and $n$. Observe and analyze the experimental results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.distributions import multinomial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.1667])\n"
     ]
    }
   ],
   "source": [
    "fair_probs = torch.ones([6]) / 6\n",
    "print(fair_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.1624, 0.1584, 0.1756, 0.1638, 0.1766, 0.1632])\n"
     ]
    }
   ],
   "source": [
    "m, n = 10, 500 \n",
    "\n",
    "counts = multinomial.Multinomial(m, fair_probs).sample((n,))\n",
    "total_counts = counts.sum(dim=0)\n",
    "estimates = total_counts / total_counts.sum()\n",
    "print(estimates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.1720, 0.1460, 0.1600, 0.1640, 0.1840, 0.1740])\n"
     ]
    }
   ],
   "source": [
    "m, n = 1, 500 \n",
    "\n",
    "counts = multinomial.Multinomial(m, fair_probs).sample((n,))\n",
    "total_counts = counts.sum(dim=0)\n",
    "estimates = total_counts / total_counts.sum()\n",
    "print(estimates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.1700, 0.1672, 0.1686, 0.1656, 0.1647, 0.1638])\n"
     ]
    }
   ],
   "source": [
    "m, n = 10, 5000\n",
    "\n",
    "counts = multinomial.Multinomial(m, fair_probs).sample((n,))\n",
    "total_counts = counts.sum(dim=0)\n",
    "estimates = total_counts / total_counts.sum()\n",
    "print(estimates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.1668, 0.1668, 0.1666, 0.1664, 0.1667, 0.1667])\n"
     ]
    }
   ],
   "source": [
    "m, n = 100, 50000\n",
    "\n",
    "counts = multinomial.Multinomial(m, fair_probs).sample((n,))\n",
    "total_counts = counts.sum(dim=0)\n",
    "estimates = total_counts / total_counts.sum()\n",
    "print(estimates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we increase the value of $m*n$, or the number of tosses of the die, we get closer to the true probabilities (The law of large numbers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2. Given two events with probability $P(A)$ and $P(B)$, compute upper and lower bounds on $P(A ∪ B)$ and $P(A ∩ B)$. (Hint: display the situation using a Venn Diagram.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bounds on $P(A ∪ B)$:\n",
    "- Upper Bound: When $A$ and $B$ are disjoint, $P(A U B)$ is maximum and equal to $P(A) + P(B)$\n",
    "- Lower Bound: When $A \\subseteq B$ or $B \\subseteq A$, $P(A U B)$ is minimum and equal to $max(P(A), P(B))$\n",
    "\n",
    "Bounds on $P(A ∩ B)$:\n",
    "- Upper Bound: When $A \\subseteq B$ or $B \\subseteq A$, $P(A U B)$ is maximum and equal to $min(P(A), P(B))$\n",
    "- Lower Bound: When $A$ and $B$ are disjoint, $P(A U B)$ is minimum and equal to $0$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q3. Assume that we have a sequence of random variables, say $A$, $B$, and $C$, where $B$ only depends on $A$, and $C$ only depends on $B$, can you simplify the joint probability $P(A, B, C)$? (Hint: this is a Markov Chain.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q4. In Section 2.6.2, the first test is more accurate. Why not run the first test twice rather than run both the first and second tests?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The second test is independent of the first test, hence we are able to simplify $P(D_1 = 1, D_2 = 1 | H = 0) = P(D_1 = 1 | H = 0)P(D_2 = 1 | H = 0)$. If the first test would have been used twice, the results would not have verified the former test, since the latter test would be dependent on the former."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
